# portfolio
This repository holds a sample of projects as supplementary material to be reviewed as part of an application.
____________________________________________________________________________________________


Greetings! 

My name is Benny Longwill and I finished my final quarter in the Computational Linguistics Master Program (CLMS) at The University of Washington last December and I look forward
to making a career in NLP!

My current research interests lie in the investigation of alternative training methods for neural language models to better generate natural language. 
My hope is that a break-through made in this area will lead to many other end-to-end systems that utilize natural language generation to directly benefit society (e.g., assistive language technology).

 As a current researcher in the University of Washington’s Computation Language and Meaning Band of Researchers (CLMBR Lab), I have conducted a master’s thesis based upon the application of 
 generative adversarial network training in order to fine-tune the BERT framework for higher quality text generation.

I am also highly interested in individualized user interaction for dialogue systems, using methods (e.g., diagnostic/probing classifiers, adversarial test sets, and artificial languages) to analyze what large neural language models learn in terms 
of syntactic and semantic knowledge, and to investigate methods to prevent these networks from adversarial attacks.
